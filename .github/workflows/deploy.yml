name: Deploy Akara Studio to AWS

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'prod'
        type: choice
        options:
          - prod
          - staging
      deploy_infra:
        description: 'Deploy infrastructure'
        required: true
        default: true
        type: boolean
      deploy_frontend:
        description: 'Deploy frontend'
        required: true
        default: true
        type: boolean
      deploy_admin:
        description: 'Deploy admin'
        required: true
        default: true
        type: boolean
      upload_sample_data:
        description: 'Upload sample catalogs'
        required: true
        default: true
        type: boolean

  push:
    branches: [ main ]
    paths: [ 'infra/**', 'frontend/**', 'admin/**' ]

  pull_request:
    branches: [ main ]
    paths: [ 'infra/**', 'frontend/**', 'admin/**' ]

env:
  AWS_REGION: us-east-1
  TF_VERSION: '1.6'
  NODE_VERSION: '18.x'
  PROJECT_NAME: akara

# Required for OIDC
permissions:
  id-token: write
  contents: read
  actions: read
  pull-requests: write

jobs:
  # Determine environment and validate inputs
  setup:
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      deploy_infra: ${{ steps.env.outputs.deploy_infra }}
      deploy_frontend: ${{ steps.env.outputs.deploy_frontend }}
      deploy_admin: ${{ steps.env.outputs.deploy_admin }}
      upload_sample_data: ${{ steps.env.outputs.upload_sample_data }}
    steps:
      - name: Determine environment
        id: env
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "environment=${{ inputs.environment }}" >> $GITHUB_OUTPUT
            echo "deploy_infra=${{ inputs.deploy_infra }}" >> $GITHUB_OUTPUT
            echo "deploy_frontend=${{ inputs.deploy_frontend }}" >> $GITHUB_OUTPUT
            echo "deploy_admin=${{ inputs.deploy_admin }}" >> $GITHUB_OUTPUT
            echo "upload_sample_data=${{ inputs.upload_sample_data }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
            echo "deploy_infra=true" >> $GITHUB_OUTPUT
            echo "deploy_frontend=true" >> $GITHUB_OUTPUT
            echo "deploy_admin=true" >> $GITHUB_OUTPUT
            echo "upload_sample_data=true" >> $GITHUB_OUTPUT
          else
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "deploy_infra=true" >> $GITHUB_OUTPUT
            echo "deploy_frontend=true" >> $GITHUB_OUTPUT
            echo "deploy_admin=true" >> $GITHUB_OUTPUT
            echo "upload_sample_data=false" >> $GITHUB_OUTPUT
          fi

  # Deploy Infrastructure with Terraform
  deploy-infrastructure:
    if: needs.setup.outputs.deploy_infra == 'true'
    needs: setup
    runs-on: ubuntu-latest
    environment: ${{ needs.setup.outputs.environment }}
    env:
      ACM_CERT_ARN: ${{ secrets.ACM_CERT_ARN }}
      TF_VAR_acm_certificate_arn: ${{ secrets.ACM_CERT_ARN }}
    outputs:
      placeholder_bucket: ${{ steps.tf_output.outputs.placeholder_bucket }}
      account_id: ${{ steps.tf_output.outputs.account_id }}
      region: ${{ steps.tf_output.outputs.region }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-${{ github.run_id }}

      - name: Show caller identity
        run: aws sts get-caller-identity

      - name: Enable bash tracing
        run: |
          echo "BASH_ENV=$GITHUB_WORKSPACE/.bashenv" >> $GITHUB_ENV
          echo "set -euxo pipefail" > .bashenv

      - name: Preflight show dirs and files
        shell: bash
        run: |
          set -euo pipefail
          echo "PWD=$(pwd)"
          ls -la
          echo "---- infra/ ----"
          ls -la infra || true
          echo "---- infra/terraform ----"
          ls -la infra/terraform || true
          echo "---- git status ----"
          git status --porcelain

      - name: Resolve AWS identity and derive backend names
        id: awsinfo
        shell: bash
        run: |
          set -euo pipefail
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          AWS_REGION=${{ env.AWS_REGION || 'us-east-1' }}
          echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_OUTPUT
          echo "AWS_REGION=$AWS_REGION" >> $GITHUB_OUTPUT
          echo "TF_STATE_BUCKET=akara-tf-state-${ACCOUNT_ID}-${AWS_REGION}" >> $GITHUB_OUTPUT
          echo "TF_LOCK_TABLE=akara-tf-locks-${ACCOUNT_ID}-${AWS_REGION}" >> $GITHUB_OUTPUT

      - name: Export TF vars
        shell: bash
        run: |
          set -euo pipefail
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          AWS_REGION=us-east-1
          export TF_VAR_account_id="$ACCOUNT_ID"
          export TF_VAR_region="$AWS_REGION"
          export TF_VAR_project="akara"
          echo "TF_VAR_account_id=$TF_VAR_account_id" >> $GITHUB_ENV
          echo "TF_VAR_region=$TF_VAR_region" >> $GITHUB_ENV
          echo "TF_VAR_project=$TF_VAR_project" >> $GITHUB_ENV
          echo "TF vars -> account_id=$TF_VAR_account_id  region=$TF_VAR_region  project=$TF_VAR_project"

      - name: Ensure Terraform backend (S3 + DynamoDB)
        shell: bash
        env:
          ACCOUNT_ID: ${{ steps.awsinfo.outputs.ACCOUNT_ID }}
          AWS_REGION: ${{ steps.awsinfo.outputs.AWS_REGION }}
        run: |
          set -euo pipefail

          # Discover account/region (already set earlier in the job; keep if present)
          ACCOUNT_ID="${ACCOUNT_ID:-$(aws sts get-caller-identity --query Account --output text)}"
          AWS_REGION="${AWS_REGION:-${{ env.AWS_REGION }}}"

          # Compute names
          STATE_BUCKET="akara-tf-state-${ACCOUNT_ID}-${AWS_REGION}"
          LOCK_TABLE="akara-tf-locks-${ACCOUNT_ID}-${AWS_REGION}"

          # Export to the whole job so later steps can read them (prevents 'unbound variable')
          echo "STATE_BUCKET=${STATE_BUCKET}" >> "$GITHUB_ENV"
          echo "LOCK_TABLE=${LOCK_TABLE}"   >> "$GITHUB_ENV"

          echo "Using STATE_BUCKET=${STATE_BUCKET}"
          echo "Using LOCK_TABLE=${LOCK_TABLE}"

          # Create state bucket if missing
          if ! aws s3api head-bucket --bucket "$STATE_BUCKET" 2>/dev/null; then
            if [ "$AWS_REGION" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "$STATE_BUCKET"
            else
              aws s3api create-bucket --bucket "$STATE_BUCKET" \
                --region "$AWS_REGION" \
                --create-bucket-configuration LocationConstraint="$AWS_REGION"
            fi
            aws s3api put-bucket-versioning --bucket "$STATE_BUCKET" --versioning-configuration Status=Enabled
            aws s3api put-public-access-block --bucket "$STATE_BUCKET" --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
          fi

          # Create/ensure DynamoDB lock table
          if ! aws dynamodb describe-table --table-name "$LOCK_TABLE" >/dev/null 2>&1; then
            aws dynamodb create-table \
              --table-name "$LOCK_TABLE" \
              --billing-mode PAY_PER_REQUEST \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH
            # wait for ACTIVE
            aws dynamodb wait table-exists --table-name "$LOCK_TABLE"
          fi

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: latest

      - name: Terraform format (write + non-fatal check)
        run: |
          terraform -chdir=infra/terraform fmt -recursive
          terraform -chdir=infra/terraform fmt -check -recursive || true
          git --no-pager diff -- infra/terraform || true

      - name: Run Terraform with comprehensive logging
        env:
          ACCOUNT_ID: ${{ steps.awsinfo.outputs.ACCOUNT_ID }}
          AWS_REGION: ${{ steps.awsinfo.outputs.AWS_REGION }}
          STATE_BUCKET: ${{ steps.awsinfo.outputs.TF_STATE_BUCKET }}
          LOCK_TABLE: ${{ steps.awsinfo.outputs.TF_LOCK_TABLE }}
          TF_VAR_project: akara
          TF_VAR_region: ${{ steps.awsinfo.outputs.AWS_REGION }}
          TF_VAR_account_id: ${{ steps.awsinfo.outputs.ACCOUNT_ID }}
          TF_VAR_frontend_domain: www.akara.studio
          TF_VAR_admin_domain: admin.akara.studio
        run: |
          set -euxo pipefail
          terraform -version
          terraform -chdir=infra/terraform init -reconfigure \
            -backend-config="bucket=${STATE_BUCKET}" \
            -backend-config="key=global/terraform.tfstate" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${LOCK_TABLE}" \
            -backend-config="encrypt=true" \
            -input=false -no-color 2>&1 | tee tf-init.log

          terraform -chdir=infra/terraform validate -no-color 2>&1 | tee tf-validate.log

      - name: Diagnose CloudFront alias ownership
        run: |
          set -euo pipefail
          echo "Looking for current owners of aliases…"
          echo "— admin.akara.studio —"
          aws cloudfront list-distributions \
            --query "DistributionList.Items[?Aliases.Items && contains(join(',',Aliases.Items), 'admin.akara.studio')].[Id,DomainName,Aliases.Items,Status]" \
            --output table || true

          echo ""
          echo "— www.akara.studio —"
          aws cloudfront list-distributions \
            --query "DistributionList.Items[?Aliases.Items && contains(join(',',Aliases.Items), 'www.akara.studio')].[Id,DomainName,Aliases.Items,Status]" \
            --output table || true

      - name: Import existing frontend distribution (idempotent, non-blocking)
        run: |
          set -euo pipefail
          echo "Checking if aws_cloudfront_distribution.frontend is already in state…"
          if terraform -chdir=infra/terraform state show aws_cloudfront_distribution.frontend >/dev/null 2>&1; then
            echo "✅ Already imported — skipping import."
          else
            echo "➡️ Importing frontend distribution ${FRONTEND_DIST_ID}…"
            # timeout prevents indefinite hangs; -input=false avoids interactivity; -no-color helps logs
            timeout 15m terraform -chdir=infra/terraform import \
              -input=false \
              -no-color \
              -lock-timeout=10m \
              aws_cloudfront_distribution.frontend ${FRONTEND_DIST_ID}
            echo "✅ Import completed."
          fi
        env:
          FRONTEND_DIST_ID: EBWBTLYBASPTD

      - name: Package Lambda functions
        run: |
          set -euo pipefail

          # fresh zips
          rm -f lambdas/get_upload_url.zip lambdas/get_catalog.zip lambdas/post_catalog.zip || true

          (cd lambdas/get_upload_url && zip -rq ../get_upload_url.zip .)
          (cd lambdas/get_catalog && zip -rq ../get_catalog.zip .)
          (cd lambdas/post_catalog && zip -rq ../post_catalog.zip .)

          # move to module dir (terraform -chdir=infra/terraform ...)
          mv lambdas/get_upload_url.zip infra/terraform/get_upload_url.zip
          mv lambdas/get_catalog.zip infra/terraform/get_catalog.zip
          mv lambdas/post_catalog.zip infra/terraform/post_catalog.zip

          echo "== ZIP listing =="
          ls -lah infra/terraform/*.zip
          echo "== Inspect each zip (should show index.js) =="
          unzip -l infra/terraform/get_upload_url.zip | sed -n '1,20p'
          unzip -l infra/terraform/get_catalog.zip    | sed -n '1,20p'
          unzip -l infra/terraform/post_catalog.zip   | sed -n '1,20p'

      - name: Show TF inputs snapshot
        run: |
          set -euo pipefail
          echo "ACM_CERT_ARN=${ACM_CERT_ARN:-(unset)}"
          echo "Expecting ZIPs:"
          ls -lah infra/terraform/*.zip

      - name: Terraform init
        run: |
          set -euxo pipefail
          terraform -chdir=infra/terraform init -reconfigure \
            -backend-config="bucket=${STATE_BUCKET}" \
            -backend-config="key=global/terraform.tfstate" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${LOCK_TABLE}"

      - name: Terraform plan (infra phase)
        run: |
          set -euxo pipefail
          terraform -chdir=infra/terraform plan -input=false -no-color \
            -lock-timeout=10m \
            -var="acm_certificate_arn=${ACM_CERT_ARN}" \
            -target=aws_s3_bucket.assets \
            -target=aws_s3_bucket_public_access_block.assets \
            -target=aws_s3_bucket_policy.assets \
            -target=aws_dynamodb_table.catalog \
            -target=aws_dynamodb_table.users \
            -target=aws_dynamodb_table.orders \
            -target=aws_apigatewayv2_api.main \
            -target=aws_apigatewayv2_stage.main \
            -target=aws_cognito_user_pool.main \
            -target=aws_cognito_user_pool_client.main \
            -out=plan.infra.out

      - name: Terraform apply (infra phase)
        run: |
          set -euxo pipefail
          terraform -chdir=infra/terraform apply -input=false -no-color -lock-timeout=10m plan.infra.out

      - name: Capture Phase 1 outputs (bucket/table)
        run: |
          set -euo pipefail
          terraform -chdir=infra/terraform output -raw assets_bucket_name     | tee /tmp/assets_bucket.txt
          terraform -chdir=infra/terraform output -raw catalog_table_name     | tee /tmp/catalog_table.txt
          echo "ASSETS_BUCKET_NAME=$(cat /tmp/assets_bucket.txt)"   >> $GITHUB_ENV
          echo "CATALOG_TABLE_NAME=$(cat /tmp/catalog_table.txt)"   >> $GITHUB_ENV
          echo "Captured:"
          echo "  ASSETS_BUCKET_NAME=$ASSETS_BUCKET_NAME"
          echo "  CATALOG_TABLE_NAME=$CATALOG_TABLE_NAME"

      - name: Sanity check env sources
        run: |
          set -euxo pipefail
          echo "Expect non-empty values:"
          terraform -chdir=infra/terraform output -raw assets_bucket_name || true
          terraform -chdir=infra/terraform output -raw catalog_table_name || true

      - name: Sanity check Phase 1 materialized names
        run: |
          set -euo pipefail
          test -n "${ASSETS_BUCKET_NAME:-}" || (echo "ASSETS_BUCKET_NAME missing"; exit 1)
          test -n "${CATALOG_TABLE_NAME:-}" || (echo "CATALOG_TABLE_NAME missing"; exit 1)
          ls -lah infra/terraform || true
          for z in get_upload_url.zip get_catalog.zip post_catalog.zip; do
            if [ ! -f "infra/terraform/$z" ]; then
              echo "Missing ZIP: infra/terraform/$z"; exit 1
            fi
            unzip -l "infra/terraform/$z" | sed -n '1,20p'
          done

      - name: Terraform plan (lambdas phase)
        run: |
          set -euxo pipefail
          terraform -chdir=infra/terraform plan -input=false -no-color \
            -lock-timeout=10m \
            -var="acm_certificate_arn=${ACM_CERT_ARN}" \
            -var="assets_bucket_name=${ASSETS_BUCKET_NAME}" \
            -var="catalog_table_name=${CATALOG_TABLE_NAME}" \
            -target=aws_lambda_function.get_upload_url \
            -target=aws_lambda_function.get_catalog \
            -target=aws_lambda_function.post_catalog \
            -target=aws_lambda_permission.get_upload_url \
            -target=aws_lambda_permission.get_catalog \
            -target=aws_lambda_permission.post_catalog \
            -target=aws_apigatewayv2_integration.get_upload_url \
            -target=aws_apigatewayv2_integration.get_catalog \
            -target=aws_apigatewayv2_integration.post_catalog \
            -target=aws_apigatewayv2_route.get_upload_url \
            -target=aws_apigatewayv2_route.get_catalog \
            -target=aws_apigatewayv2_route.post_catalog \
            -target=aws_apigatewayv2_authorizer.cognito \
            -out=plan.lambdas.out

      - name: Terraform apply (lambdas phase)
        run: |
          set -euxo pipefail
          terraform -chdir=infra/terraform apply -input=false -no-color -lock-timeout=10m plan.lambdas.out

      - name: Get Terraform Outputs
        id: tf_output
        run: |
          echo "placeholder_bucket=$(terraform -chdir=infra/terraform output -raw placeholder_bucket)" >> $GITHUB_OUTPUT
          echo "account_id=$(terraform -chdir=infra/terraform output -raw account_id)" >> $GITHUB_OUTPUT
          echo "region=$(terraform -chdir=infra/terraform output -raw region)" >> $GITHUB_OUTPUT
          echo "cognito_user_pool_id=$(terraform -chdir=infra/terraform output -raw cognito_user_pool_id)" >> $GITHUB_OUTPUT

      - name: Ensure Cognito groups exist
        if: ${{ inputs.deploy_infra == 'true' }}
        env:
          COGNITO_POOL_ID: ${{ steps.tf_output.outputs.cognito_user_pool_id }}
        run: |
          set -euo pipefail
          aws cognito-idp create-group --user-pool-id "$COGNITO_POOL_ID" --group-name admin || true
          aws cognito-idp create-group --user-pool-id "$COGNITO_POOL_ID" --group-name user  || true

      - name: Save Infrastructure Outputs
        run: |
          terraform -chdir=infra/terraform output -json > infrastructure-outputs.json
          
      - name: Upload Infrastructure Outputs
        uses: actions/upload-artifact@v4
        with:
          name: infrastructure-outputs-${{ needs.setup.outputs.environment }}
          path: infrastructure-outputs.json

      - name: Upload TF logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: infra-logs
          path: |
            tf-*.log
            infra/terraform/*.tf
            infra/terraform/.terraform/**/*
          if-no-files-found: ignore

  # Build and Deploy Frontend
  deploy-frontend:
    if: needs.setup.outputs.deploy_frontend == 'true'
    needs: [setup, deploy-infrastructure]
    runs-on: ubuntu-latest
    environment: ${{ needs.setup.outputs.environment }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Frontend-${{ github.run_id }}

      - name: Detect root package manager
        id: detect_root_pm
        run: |
          if [ -f package-lock.json ]; then
            echo "pm=npm" >> $GITHUB_OUTPUT
            echo "lockfile=package-lock.json" >> $GITHUB_OUTPUT
          elif [ -f yarn.lock ]; then
            echo "pm=yarn" >> $GITHUB_OUTPUT
            echo "lockfile=yarn.lock" >> $GITHUB_OUTPUT
          else
            echo "No root lockfile found"
            echo "pm=none" >> $GITHUB_OUTPUT
            echo "lockfile=" >> $GITHUB_OUTPUT
          fi

      - name: Setup Node.js (root workspace)
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: ${{ steps.detect_root_pm.outputs.pm }}
          cache-dependency-path: ${{ steps.detect_root_pm.outputs.lockfile }}

      - name: Install workspace deps
        run: |
          if [ "${{ steps.detect_root_pm.outputs.pm }}" = "npm" ]; then
            npm ci
          else
            yarn install --frozen-lockfile
          fi

      - name: Download infra outputs
        uses: actions/download-artifact@v4
        with:
          name: infrastructure-outputs-${{ needs.setup.outputs.environment }}
          path: .

      - name: Export FRONTEND_BUCKET & FRONTEND_DISTRIBUTION from outputs
        run: |
          echo "FRONTEND_BUCKET=$(jq -r .frontend_bucket.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "FRONTEND_DIST=$(jq -r .frontend_distribution_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "FRONTEND_DOMAIN=$(jq -r .frontend_domain.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "API_BASE_URL=$(jq -r .api_base_url.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "COGNITO_USER_POOL_ID=$(jq -r .cognito_user_pool_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "COGNITO_CLIENT_ID=$(jq -r .cognito_user_pool_client_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "AWS_REGION_OUTPUT=$(jq -r .aws_region.value infrastructure-outputs.json)" >> $GITHUB_ENV

      - name: Build Frontend
        working-directory: frontend
        env:
          NEXT_PUBLIC_CDN_URL: https://${{ env.FRONTEND_DOMAIN }}
          NEXT_PUBLIC_API_BASE_URL: ${{ env.API_BASE_URL }}
          NEXT_PUBLIC_ASSETS_CDN_URL: https://${{ env.FRONTEND_DOMAIN }}/content
          NEXT_PUBLIC_COGNITO_USER_POOL_ID: ${{ env.COGNITO_USER_POOL_ID }}
          NEXT_PUBLIC_COGNITO_CLIENT_ID: ${{ env.COGNITO_CLIENT_ID }}
          NEXT_PUBLIC_AWS_REGION: ${{ env.AWS_REGION_OUTPUT }}
          NEXT_PUBLIC_SITE_URL: ${{ needs.setup.outputs.environment == 'prod' && 'https://akara.studio' || 'https://staging.akara.studio' }}
          NEXT_PUBLIC_ENVIRONMENT: ${{ needs.setup.outputs.environment }}
        run: |
          if [ "${{ steps.detect_root_pm.outputs.pm }}" = "npm" ]; then
            npm run build
          else
            yarn build
          fi

      - name: Sync to S3 (frontend)
        run: |
          aws s3 sync frontend/out "s3://$FRONTEND_BUCKET" --delete
          aws cloudfront create-invalidation --distribution-id "$FRONTEND_DIST" --paths "/*"

      - name: Frontend Deployment Summary
        run: |
          echo "✅ Frontend deployed successfully!"
          echo "🌐 CloudFront URL: https://$FRONTEND_DOMAIN"
          echo "📦 Placeholder bucket: ${{ needs.deploy-infrastructure.outputs.placeholder_bucket }}"
          echo "🏗️ Infrastructure test completed for account: ${{ needs.deploy-infrastructure.outputs.account_id }}"

  # Upload Sample Catalogs
  upload-sample-data:
    if: needs.setup.outputs.upload_sample_data == 'true'
    needs: [setup, deploy-infrastructure, deploy-frontend]
    runs-on: ubuntu-latest
    environment: ${{ needs.setup.outputs.environment }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Data-${{ github.run_id }}

      - name: Sample Data Upload Summary
        run: |
          echo "✅ Sample data step completed!"
          echo "📚 Using placeholder bucket: ${{ needs.deploy-infrastructure.outputs.placeholder_bucket }}"
          echo "🎯 This is a minimal infrastructure test - full deployment coming in Phase 1"

  # Build and Deploy Admin
  deploy-admin:
    if: needs.setup.outputs.deploy_admin == 'true'
    needs: [setup, deploy-infrastructure]
    runs-on: ubuntu-latest
    environment: ${{ needs.setup.outputs.environment }}
    outputs:
      admin_cloudfront_domain: ${{ steps.admin_cf.outputs.domain }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Admin-${{ github.run_id }}

      - name: Detect root package manager
        id: detect_root_pm_admin
        run: |
          if [ -f package-lock.json ]; then
            echo "pm=npm" >> $GITHUB_OUTPUT
            echo "lockfile=package-lock.json" >> $GITHUB_OUTPUT
          elif [ -f yarn.lock ]; then
            echo "pm=yarn" >> $GITHUB_OUTPUT
            echo "lockfile=yarn.lock" >> $GITHUB_OUTPUT
          else
            echo "No root lockfile found"
            echo "pm=none" >> $GITHUB_OUTPUT
            echo "lockfile=" >> $GITHUB_OUTPUT
          fi

      - name: Setup Node.js (root workspace)
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: ${{ steps.detect_root_pm_admin.outputs.pm }}
          cache-dependency-path: ${{ steps.detect_root_pm_admin.outputs.lockfile }}

      - name: Install workspace deps
        run: |
          if [ "${{ steps.detect_root_pm_admin.outputs.pm }}" = "npm" ]; then
            npm ci
          else
            yarn install --frozen-lockfile
          fi

      - name: Download infra outputs
        uses: actions/download-artifact@v4
        with:
          name: infrastructure-outputs-${{ needs.setup.outputs.environment }}
          path: .

      - name: Export ADMIN_BUCKET & ADMIN_DISTRIBUTION from outputs
        run: |
          echo "ADMIN_BUCKET=$(jq -r .admin_bucket.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "ADMIN_DIST=$(jq -r .admin_distribution_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "ADMIN_DOMAIN=$(jq -r .admin_domain.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "API_BASE_URL=$(jq -r .api_base_url.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "COGNITO_USER_POOL_ID=$(jq -r .cognito_user_pool_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "COGNITO_CLIENT_ID=$(jq -r .cognito_user_pool_client_id.value infrastructure-outputs.json)" >> $GITHUB_ENV
          echo "AWS_REGION_OUTPUT=$(jq -r .aws_region.value infrastructure-outputs.json)" >> $GITHUB_ENV

      - name: Build Admin
        working-directory: admin
        env:
          NEXT_PUBLIC_API_BASE_URL: ${{ env.API_BASE_URL }}
          NEXT_PUBLIC_ASSETS_CDN_URL: https://${{ env.ADMIN_DOMAIN }}/content
          NEXT_PUBLIC_COGNITO_USER_POOL_ID: ${{ env.COGNITO_USER_POOL_ID }}
          NEXT_PUBLIC_COGNITO_CLIENT_ID: ${{ env.COGNITO_CLIENT_ID }}
          NEXT_PUBLIC_AWS_REGION: ${{ env.AWS_REGION_OUTPUT }}
          NEXT_PUBLIC_ENVIRONMENT: ${{ needs.setup.outputs.environment }}
        run: |
          if [ "${{ steps.detect_root_pm_admin.outputs.pm }}" = "npm" ]; then
            npm run build
          else
            yarn build
          fi

      - name: Sync to S3 (admin)
        run: |
          aws s3 sync admin/out "s3://$ADMIN_BUCKET" --delete
          aws cloudfront create-invalidation --distribution-id "$ADMIN_DIST" --paths "/*"

      - name: Admin Deployment Summary
        run: |
          echo "✅ Admin deployed successfully!"
          echo "🌐 CloudFront URL: https://$ADMIN_DOMAIN"
          echo "👤 Admin test completed for account: ${{ needs.deploy-infrastructure.outputs.account_id }}"
          echo "🎯 This is a minimal infrastructure test - full admin deployment coming in Phase 1"

  # Final Deployment Summary
  deployment-summary:
    needs: [setup, deploy-infrastructure, deploy-frontend, deploy-admin, upload-sample-data]
    if: always() && (needs.deploy-infrastructure.result == 'success' || needs.deploy-frontend.result == 'success' || needs.deploy-admin.result == 'success')
    runs-on: ubuntu-latest
    steps:
      - name: Download infra outputs
        uses: actions/download-artifact@v4
        with:
          name: infrastructure-outputs-${{ needs.setup.outputs.environment }}
          path: .

      - name: Show CloudFront URLs
        run: |
          FRONTEND_DOMAIN=$(jq -r .frontend_domain.value infrastructure-outputs.json)
          ADMIN_DOMAIN=$(jq -r .admin_domain.value infrastructure-outputs.json)
          echo "🌐 **Frontend**: https://$FRONTEND_DOMAIN"
          echo "👤 **Admin**:    https://$ADMIN_DOMAIN"

      - name: Generate Infrastructure Test Results
        run: |
          FRONTEND_DOMAIN=$(jq -r .frontend_domain.value infrastructure-outputs.json)
          ADMIN_DOMAIN=$(jq -r .admin_domain.value infrastructure-outputs.json)
          
          echo "# 🎉 Akara Studio Production Deployment Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 🌐 Live URLs" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Frontend**: https://$FRONTEND_DOMAIN" >> $GITHUB_STEP_SUMMARY
          echo "**Admin**: https://$ADMIN_DOMAIN" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ✅ Infrastructure Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**AWS Account:** ${{ needs.deploy-infrastructure.outputs.account_id }}" >> $GITHUB_STEP_SUMMARY
          echo "**Region:** ${{ needs.deploy-infrastructure.outputs.region }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 🎯 Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **OIDC Authentication**: Working" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Terraform Backend**: Self-bootstrapping successful" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **AWS Permissions**: IAM role has required access" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Frontend Build**: Next.js compilation successful" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Admin Build**: Next.js compilation successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 🚀 Ready for Phase 1" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The infrastructure foundation is working correctly!" >> $GITHUB_STEP_SUMMARY
          echo "Next: Deploy full S3, CloudFront, DynamoDB, and Cognito resources." >> $GITHUB_STEP_SUMMARY

      - name: Create Infrastructure Test Report
        run: |
          cat > INFRASTRUCTURE-TEST-REPORT.txt << EOF
          Akara Studio - Infrastructure Test Report
          =========================================
          
          Test Date: $(date -u)
          Environment: ${{ needs.setup.outputs.environment }}
          AWS Account: ${{ needs.deploy-infrastructure.outputs.account_id }}
          AWS Region: ${{ needs.deploy-infrastructure.outputs.region }}
          
          INFRASTRUCTURE VALIDATION:
          -------------------------
          ✅ OIDC Authentication: Working
          ✅ Terraform Backend: Self-bootstrapping successful  
          ✅ AWS Permissions: IAM role has required access
          ✅ S3 Operations: Bucket creation successful
          ✅ Frontend Build: Next.js compilation successful
          ✅ Admin Build: Next.js compilation successful
          
          TEST RESOURCES CREATED:
          ----------------------
          - Test S3 Bucket: ${{ needs.deploy-infrastructure.outputs.placeholder_bucket }}
          - Terraform State Bucket: Dynamic (account-unique)
          - DynamoDB Lock Table: Dynamic (account-unique)
          
          NEXT STEPS:
          ----------
          1. ✅ Infrastructure foundation is working
          2. 🚀 Ready to deploy full Phase 1 resources
          3. 🎯 Next: Add S3, CloudFront, DynamoDB, Cognito to main.tf
          4. 🌐 Deploy complete frontend and admin with real CloudFront URLs
          EOF

      - name: Upload Infrastructure Test Report
        uses: actions/upload-artifact@v4
        with:
          name: infrastructure-test-report-${{ needs.setup.outputs.environment }}
          path: INFRASTRUCTURE-TEST-REPORT.txt
